{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduzione\n",
    "\n",
    "I **sistemi di raccomandazione** sono dei sistemi software che permettono di predire le preferenze di un utente basandoci sulle preferenze espresse dall'utente in passato.  \n",
    "A differenza dei sistemi tradizionali, essi possono predire il gradimento dell'utente anche per oggetti rari, evitando il cosiddetto fenomeno **long-tail**.  \n",
    "Un sistema di raccomandazione è strutturato in una matrice chiamata **matrice di utilità**, avente:  \n",
    "- nelle righe, gli utenti del sistema.  \n",
    "- nelle colonne, gli oggetti da valutare.  \n",
    "- nelle celle, la valutazione dell'oggetto nella colonna `j` relativa all'utente nella riga `i`.  \n",
    "\n",
    "I sistemi di raccomandazione possono diversi in due categorie:  \n",
    "-  **content-based**: ad ogni utente è associato un profilo che verrà utilizzato per effettuare le predizioni sugli item.  \n",
    "- **collaborative-filtering**: le predizioni sugli item vengono fatte basandoci su utenti simili (nel caso di **user-based** collaborative filtering) oppure su item simili (nel caso di **item-based** collaborative filtering).  \n",
    "\n",
    "### Obbiettivo\n",
    "Creeremo diversi sistemi di raccomandazione e ne confronteremo le prestazioni. Useremo anche un sistema personalizzato che tenga in considerazione delle data in cui è stata lasciata la valutazione.  \n",
    "Useremo la versione ridotta di questo [dataset](https://grouplens.org/datasets/movielens/latest/) per generare i sistemi. Al suo interno sono presenti due tabelle `.csv`:  \n",
    "- `movies.csv`: contiene l'elenco dei film, con i campi `movieId`, `title` e `genres`.  \n",
    "- `ratings.csv`: contiene l'elenco delle valutazione relative agli utenti, con i campi `userId`, `movieId`, `rating`, `timestamp`. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparazione dell'ambiente\n",
    "All'interno del nostro progetto, useremo diverse librerie:  \n",
    "- [`pandas`](https://pandas.pydata.org/), permette di all'interno i dati all'interno .  \n",
    "- [`surprise`](https://surpriselib.com/), permette la creazione e l'addestramento dei sistemi di raccomandazione in Python.  \n",
    "\n",
    "Iniziamo leggendo dal file `movies.csv` i film e dal file `ratings.csv` le valutazioni degli utenti.\n",
    "Successivamente, rimuoviamo dai dataset eventuali righe che contengono valori `NaN` poiché potrebbero compromettere il risultato finale dell'analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "movie_dataset_path = os.path.join(os.getcwd(), 'movie-dataset', 'movies.csv')\n",
    "rating_dataset_path = os.path.join(os.getcwd(), 'movie-dataset', 'ratings.csv')\n",
    "\n",
    "movie_dataset = pd.read_csv(movie_dataset_path, sep=',', engine='python')\n",
    "rating_dataset = pd.read_csv(rating_dataset_path, sep=',', engine='python')\n",
    "\n",
    "movie_dataset = movie_dataset.dropna()\n",
    "rating_dataset = rating_dataset.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta preparati i dataset, possiamo procedere con la conversione del dataset in una struttura dati che verrà utilizzata per l'addestramento dei sistemi di raccomandazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "elaborated_data = Dataset.load_from_df(rating_dataset[['userId', 'movieId', 'rating']], Reader(rating_scale=(0.5, 5.0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi dei dati\n",
    "Dal dataset `ratings.csv` possiamo estrarre alcune informazioni utili per l'analisi dei dati.\n",
    "In particolare, possiamo ricavare l'elenco degli utenti che hanno lasciato almeno una valutazione.\n",
    "Il comportamento degli utenti può già darci una prima idea di come sarà la struttura della matrice di utilità.\n",
    "\n",
    "Procediamo quindi ad estrarre dal dataset delle valutazione tutti gli utenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>mean</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>4.363284</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>739163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.948276</td>\n",
       "      <td>4.007142</td>\n",
       "      <td>0.058866</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.435897</td>\n",
       "      <td>2.287578</td>\n",
       "      <td>0.148320</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.480049</td>\n",
       "      <td>0.075507</td>\n",
       "      <td>62496114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>3.667064</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>3.657399</td>\n",
       "      <td>3.640449</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>197231731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>3.786096</td>\n",
       "      <td>3.710835</td>\n",
       "      <td>0.075261</td>\n",
       "      <td>34768995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>3.134176</td>\n",
       "      <td>3.250530</td>\n",
       "      <td>0.116354</td>\n",
       "      <td>72402187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>3.270270</td>\n",
       "      <td>3.238706</td>\n",
       "      <td>0.031564</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>610</td>\n",
       "      <td>3.688556</td>\n",
       "      <td>3.589850</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>16417448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId      mean  weighted_mean  mean_diff  time_diff\n",
       "1        1  4.366379       4.363284   0.003095     739163\n",
       "2        2  3.948276       4.007142   0.058866        505\n",
       "3        3  2.435897       2.287578   0.148320        970\n",
       "4        4  3.555556       3.480049   0.075507   62496114\n",
       "5        5  3.636364       3.667064   0.030700        590\n",
       "..     ...       ...            ...        ...        ...\n",
       "606    606  3.657399       3.640449   0.016951  197231731\n",
       "607    607  3.786096       3.710835   0.075261   34768995\n",
       "608    608  3.134176       3.250530   0.116354   72402187\n",
       "609    609  3.270270       3.238706   0.031564        278\n",
       "610    610  3.688556       3.589850   0.098706   16417448\n",
       "\n",
       "[610 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "users_list = rating_dataset['userId'].unique().tolist()\n",
    "users_dataset = pd.DataFrame(columns=['userId', 'mean', 'weighted_mean', 'mean_diff', 'time_diff'])\n",
    "\n",
    "def map_range(x, in_min, in_max, out_min = 0.5, out_max = 1.5):\n",
    "    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "\n",
    "for user in users_list:\n",
    "    single_ratings = rating_dataset[rating_dataset['userId'] == user]\n",
    "    single_last_timestamp = single_ratings['timestamp'].max()\n",
    "    single_first_timestamp = single_ratings['timestamp'].min()\n",
    "    user_ratings = single_ratings['rating'].tolist()\n",
    "    user_timestamps = list(map(lambda x: map_range(x, single_first_timestamp, single_last_timestamp), single_ratings['timestamp'].tolist()))\n",
    "    user_mean = np.mean(user_ratings)\n",
    "    user_weighted_mean = np.average(user_ratings, weights=user_timestamps)\n",
    "    user_mean_diff = abs(user_mean - user_weighted_mean)\n",
    "    user_time_diff = single_last_timestamp - single_first_timestamp\n",
    "    users_dataset = pd.concat([users_dataset, pd.DataFrame([[user, user_mean, user_weighted_mean, user_mean_diff, user_time_diff]], columns=['userId', 'mean', 'weighted_mean', 'mean_diff', 'time_diff'], index=[user])])\n",
    "    \n",
    "users_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase, accuracy\n",
    "from surprise.model_selection import KFold, train_test_split\n",
    "\n",
    "\n",
    "def test_algorithm(algorithm: AlgoBase):\n",
    "    train, test = train_test_split(elaborated_data, test_size=0.2)\n",
    "    algorithm.fit(train)\n",
    "    split_predictions = algorithm.test(test)\n",
    "    split_predictions_measure = dict()\n",
    "    split_predictions_measure['rmse'] = accuracy.rmse(split_predictions, verbose=False)\n",
    "    split_predictions_measure['mae'] = accuracy.mae(split_predictions, verbose=False)\n",
    "    split_predictions_measure['mse'] = accuracy.mse(split_predictions, verbose=False)\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    cross_predictions_measure = dict()\n",
    "    cross_predictions_measure['rmse'] = np.array([])\n",
    "    cross_predictions_measure['mae'] = np.array([])\n",
    "    cross_predictions_measure['mse'] = np.array([])\n",
    "    for k_train, k_test in kf.split(elaborated_data):\n",
    "        algorithm.fit(k_train)\n",
    "        k_predictions = algorithm.test(k_test)\n",
    "        cross_predictions_measure['rmse'] = np.append(cross_predictions_measure['rmse'], accuracy.rmse(k_predictions, verbose=False))\n",
    "        cross_predictions_measure['mae'] = np.append(cross_predictions_measure['mae'], accuracy.mae(k_predictions, verbose=False))\n",
    "        cross_predictions_measure['mse'] = np.append(cross_predictions_measure['mse'], accuracy.mse(k_predictions, verbose=False))\n",
    "    \n",
    "    return (split_predictions_measure, cross_predictions_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Split RMSE</th>\n",
       "      <th>Split MAE</th>\n",
       "      <th>Split MSE</th>\n",
       "      <th>Cross RMSE</th>\n",
       "      <th>Cross MAE</th>\n",
       "      <th>Cross MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.866909</td>\n",
       "      <td>0.665146</td>\n",
       "      <td>0.751532</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.671654</td>\n",
       "      <td>0.764558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNNBaseline</td>\n",
       "      <td>0.877804</td>\n",
       "      <td>0.669219</td>\n",
       "      <td>0.770539</td>\n",
       "      <td>0.874354</td>\n",
       "      <td>0.667925</td>\n",
       "      <td>0.764520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>0.941845</td>\n",
       "      <td>0.722927</td>\n",
       "      <td>0.887071</td>\n",
       "      <td>0.948575</td>\n",
       "      <td>0.726612</td>\n",
       "      <td>0.899813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>0.898913</td>\n",
       "      <td>0.685380</td>\n",
       "      <td>0.808044</td>\n",
       "      <td>0.896619</td>\n",
       "      <td>0.685316</td>\n",
       "      <td>0.803966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>0.906272</td>\n",
       "      <td>0.686977</td>\n",
       "      <td>0.821329</td>\n",
       "      <td>0.896885</td>\n",
       "      <td>0.680089</td>\n",
       "      <td>0.804410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm  Split RMSE  Split MAE  Split MSE  Cross RMSE  Cross MAE   \n",
       "0            SVD    0.866909   0.665146   0.751532    0.874372   0.671654  \\\n",
       "1    KNNBaseline    0.877804   0.669219   0.770539    0.874354   0.667925   \n",
       "2       KNNBasic    0.941845   0.722927   0.887071    0.948575   0.726612   \n",
       "3   KNNWithMeans    0.898913   0.685380   0.808044    0.896619   0.685316   \n",
       "4  KNNWithZScore    0.906272   0.686977   0.821329    0.896885   0.680089   \n",
       "\n",
       "   Cross MSE  \n",
       "0   0.764558  \n",
       "1   0.764520  \n",
       "2   0.899813  \n",
       "3   0.803966  \n",
       "4   0.804410  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "\n",
    "algorithms = list([SVD(), KNNBaseline(k=40, verbose=False), KNNBasic(k=40, verbose=False), KNNWithMeans(k=40, verbose=False), KNNWithZScore(k=40, verbose=False)])\n",
    "algorithms_results = pd.DataFrame(columns=['Algorithm', 'Split RMSE', 'Split MAE', 'Split MSE', 'Cross RMSE', 'Cross MAE', 'Cross MSE'])\n",
    "\n",
    "for algo in algorithms:\n",
    "    split_result, cross_result = test_algorithm(algo)\n",
    "    result_df = pd.DataFrame({\n",
    "        'Algorithm': algo.__class__.__name__, \n",
    "        'Split RMSE': split_result['rmse'], \n",
    "        'Split MAE': split_result['mae'], \n",
    "        'Split MSE': split_result['mse'], \n",
    "        'Cross RMSE': cross_result['rmse'].mean(), \n",
    "        'Cross MAE': cross_result['mae'].mean(), \n",
    "        'Cross MSE': cross_result['mse'].mean()\n",
    "    }, index=[0])\n",
    "    algorithms_results = pd.concat([algorithms_results, result_df], ignore_index=True)\n",
    "    \n",
    "algorithms_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('python-reccomendation-XMPX0F2E')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68d2b6b8a1c82637b047727f5e628000fa094bf771643027fb9a5034d8507928"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
